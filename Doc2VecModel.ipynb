{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from numpy import loadtxt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel(\"BQ Analysis v1_1.xlsx\", \"Project BQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 424 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.astype(str)\n",
    "df[\"PREPROCESS_TEXT\"] = df[\"BQ_TRADE\"] + \",\" + df[\"BQ_HEADING\"] + \",\" + df[\"BQ_SUB_HEADING\"] + \",\" + df[\"BQ_ITEM_HEADING\"] + \",\" + df[\"BQ_ITEM_DESCRIPTION\"] #+ \",\" + df[\"AC_TRADE_CODE\"]\n",
    "#df['RESULT'] = \"\"\n",
    "#training_df = df.loc[df['CONTRACT_CODE'] == \"FL49\"].copy() // not enough training data?\n",
    "df = df[df['AC_TRADE_CODE'] != \"DA\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"IP\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"SS\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"EL\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"SO\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"AS\"]\n",
    "#training_df = df[df['CONTRACT_CODE'] != \"QHP3\"]\n",
    "#test_df = df[df['CONTRACT_CODE'] == \"QHP3\"]\n",
    "\n",
    "df[\"PREPROCESS_TEXT\"] = list(map(lambda x: x.lower(), list(df[\"PREPROCESS_TEXT\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_doc = []\n",
    "for d in df[\"PREPROCESS_TEXT\"]:\n",
    "    tokenized_doc.append(word_tokenize(d))\n",
    "tokenized_doc\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "len(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.0771446 , -0.61915094,  0.25852293, ..., -0.41830614,\n",
       "        -0.3539744 , -0.05639476],\n",
       "       [-0.43415785, -0.09482994,  0.01738744, ..., -0.86261576,\n",
       "        -0.16823775, -1.2110382 ],\n",
       "       [-0.76517767, -0.40562192, -0.09901154, ..., -0.9129757 ,\n",
       "         0.16725577, -0.1546226 ],\n",
       "       ...,\n",
       "       [ 0.01008305, -0.6439089 , -0.9389761 , ...,  0.272711  ,\n",
       "         0.15421653,  0.20070341],\n",
       "       [-0.07685632,  0.35804367, -0.6021043 , ...,  0.06386675,\n",
       "         0.4388449 , -1.2792351 ],\n",
       "       [ 0.78829527, -0.4805456 , -0.6270536 , ..., -0.18057649,\n",
       "         0.69437975, -0.38539076]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 100)\n",
    "# Save trained doc2vec model\n",
    "model.save(\"test_doc2vec.model\")\n",
    "# Load saved doc2vec model\n",
    "model= Doc2Vec.load(\"test_doc2vec.model\")\n",
    "model.wv.vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(len(df[\"AC_TRADE_CODE\"]))\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(df[\"AC_TRADE_CODE\"])\n",
    "# training_label = np_utils.to_categorical((label_encoder.transform(df[\"AC_TRADE_CODE\"])))\n",
    "\n",
    "# print(len(training_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
