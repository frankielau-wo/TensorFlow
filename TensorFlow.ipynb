{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from numpy import loadtxt\n",
    "from keras.utils import np_utils\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel(\"BQ Analysis v1_1.xlsx\", \"Project BQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.astype(str)\n",
    "df[\"PREPROCESS_TEXT\"] = df[\"BQ_TRADE\"] + \",\" + df[\"BQ_HEADING\"] + \",\" + df[\"BQ_SUB_HEADING\"] + \",\" + df[\"BQ_ITEM_HEADING\"] + \",\" + df[\"BQ_ITEM_DESCRIPTION\"] #+ \",\" + df[\"AC_TRADE_CODE\"]\n",
    "#df['RESULT'] = \"\"\n",
    "#training_df = df.loc[df['CONTRACT_CODE'] == \"FL49\"].copy() // not enough training data?\n",
    "df = df[df['AC_TRADE_CODE'] != \"DA\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"IP\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"SS\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"EL\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"SO\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"AS\"]\n",
    "\n",
    "\n",
    "df[\"PREPROCESS_TEXT\"] = list(map(lambda x: x.lower(), list(df[\"PREPROCESS_TEXT\"])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['PS',\n",
    "'ST',\n",
    "'SM',\n",
    "'EL',\n",
    "'PL',\n",
    "'BS',\n",
    "'DR',\n",
    "'CJ',\n",
    "'PA',\n",
    "'AR',\n",
    "'PR',\n",
    "'SO',\n",
    "'GL',\n",
    "'IF',\n",
    "'DW',\n",
    "'EX',\n",
    "'IR',\n",
    "'FD',\n",
    "'AP',\n",
    "'SU',\n",
    "'FF',\n",
    "'SG',\n",
    "'AS',\n",
    "'EF',\n",
    "'BR',\n",
    "'SS',\n",
    "'DA',\n",
    "'IP'\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = df[df['CONTRACT_CODE'] != \"QHP3\"].copy()\n",
    "\n",
    "\n",
    "training_df[\"AC_TRADE_CODE_INDEX\"] = list(map(lambda x: class_names.index(x), list(training_df.AC_TRADE_CODE)))\n",
    "#training_df[\"AC_TRADE_CODE\"].value_counts()\n",
    "#training_df[\"AC_TRADE_CODE_INDEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2788\n",
       "1     2712\n",
       "2     2258\n",
       "4      853\n",
       "6      479\n",
       "8      427\n",
       "7      368\n",
       "9      215\n",
       "12      95\n",
       "10      58\n",
       "24      35\n",
       "16      24\n",
       "15      10\n",
       "Name: AC_TRADE_CODE_INDEX, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df[df['CONTRACT_CODE'] == \"QHP3\"].copy()\n",
    "test_df[\"AC_TRADE_CODE_INDEX\"] = list(map(lambda x: class_names.index(x), list(test_df.AC_TRADE_CODE)))\n",
    "test_df[\"AC_TRADE_CODE_INDEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[\"AC_TRADE_CODE\"]))\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(df[\"AC_TRADE_CODE\"])\n",
    "# training_label = np_utils.to_categorical((label_encoder.transform(df[\"AC_TRADE_CODE\"])))\n",
    "\n",
    "# print(len(training_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized_doc = []\n",
    "# for d in training_df[\"PREPROCESS_TEXT\"]:\n",
    "#     tokenized_doc.append(word_tokenize(d))\n",
    "# tokenized_doc\n",
    "# tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "# len(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model= Doc2Vec.load(\"test_doc2vec.model\")\n",
    "#training_text = model.wv.vectors\n",
    "#print(len(training_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31075\n",
      "[-0.07133482 -0.08574978 -0.41277137 -0.63597965 -0.91471535  0.28850505\n",
      " -0.53576374 -0.90945405 -1.5025458  -0.61843145 -0.48765257  0.3181048\n",
      " -0.10366034 -1.4194092   0.6623187   0.8691084  -0.16303876  0.806646\n",
      "  0.8260437   1.0821548 ]\n",
      "10322\n",
      "[ 0.47780302  1.2907476  -1.1757203   0.54326457  0.48385    -1.4731838\n",
      " -0.08764178  0.01109768 -0.37486562 -0.18048786  0.98855644  0.6542719\n",
      "  1.7492304   0.11882848  0.3736593  -0.6452582  -0.6972129   1.0269859\n",
      " -0.31154588  2.3005223 ]\n",
      "Wall time: 6min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test_data = word_tokenize(df[\"PREPROCESS_TEXT\"])\n",
    "# v1 = model.infer_vector(test_data)\n",
    "# print(\"V1_infer\", v1)\n",
    "\n",
    "training_text = []\n",
    "for index, row in training_df.iterrows():\n",
    "    training_text.append(model.infer_vector(word_tokenize(row[\"PREPROCESS_TEXT\"])))\n",
    "\n",
    "training_text = np.asarray(training_text)  \n",
    "print(len(training_text))\n",
    "print(training_text[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_text = []\n",
    "for index, row in test_df.iterrows():\n",
    "    #print(model.infer_vector(word_tokenize(row[\"PREPROCESS_TEXT\"])))\n",
    "    test_text.append(model.infer_vector(word_tokenize(row[\"PREPROCESS_TEXT\"])))\n",
    "\n",
    "test_text = np.asarray(test_text)  \n",
    "print(len(test_text))\n",
    "print(test_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = np.asarray(training_df[\"AC_TRADE_CODE_INDEX\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31075, 20), (31075,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text.shape, training_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "972/972 [==============================] - 1s 822us/step - loss: 1.4920 - accuracy: 0.6134\n",
      "Epoch 2/100\n",
      "972/972 [==============================] - 1s 798us/step - loss: 0.5886 - accuracy: 0.8239\n",
      "Epoch 3/100\n",
      "972/972 [==============================] - 1s 845us/step - loss: 0.4963 - accuracy: 0.8508\n",
      "Epoch 4/100\n",
      "972/972 [==============================] - 1s 899us/step - loss: 0.4447 - accuracy: 0.8626\n",
      "Epoch 5/100\n",
      "972/972 [==============================] - 1s 866us/step - loss: 0.4098 - accuracy: 0.8737\n",
      "Epoch 6/100\n",
      "972/972 [==============================] - 1s 828us/step - loss: 0.3812 - accuracy: 0.8835\n",
      "Epoch 7/100\n",
      "972/972 [==============================] - 1s 806us/step - loss: 0.3454 - accuracy: 0.8928\n",
      "Epoch 8/100\n",
      "972/972 [==============================] - 1s 911us/step - loss: 0.3388 - accuracy: 0.8990\n",
      "Epoch 9/100\n",
      "972/972 [==============================] - 1s 887us/step - loss: 0.3233 - accuracy: 0.9031\n",
      "Epoch 10/100\n",
      "972/972 [==============================] - 1s 818us/step - loss: 0.2999 - accuracy: 0.9098\n",
      "Epoch 11/100\n",
      "972/972 [==============================] - 1s 837us/step - loss: 0.2862 - accuracy: 0.9132\n",
      "Epoch 12/100\n",
      "972/972 [==============================] - 1s 907us/step - loss: 0.2818 - accuracy: 0.9146\n",
      "Epoch 13/100\n",
      "972/972 [==============================] - 1s 854us/step - loss: 0.2679 - accuracy: 0.9174\n",
      "Epoch 14/100\n",
      "972/972 [==============================] - 1s 965us/step - loss: 0.2607 - accuracy: 0.9203\n",
      "Epoch 15/100\n",
      "972/972 [==============================] - 1s 823us/step - loss: 0.2493 - accuracy: 0.9244\n",
      "Epoch 16/100\n",
      "972/972 [==============================] - 1s 842us/step - loss: 0.2619 - accuracy: 0.9233\n",
      "Epoch 17/100\n",
      "972/972 [==============================] - 1s 849us/step - loss: 0.2384 - accuracy: 0.9254\n",
      "Epoch 18/100\n",
      "972/972 [==============================] - 1s 767us/step - loss: 0.2410 - accuracy: 0.9273\n",
      "Epoch 19/100\n",
      "972/972 [==============================] - 1s 720us/step - loss: 0.2221 - accuracy: 0.9326\n",
      "Epoch 20/100\n",
      "972/972 [==============================] - 1s 723us/step - loss: 0.2276 - accuracy: 0.9317\n",
      "Epoch 21/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.2188 - accuracy: 0.9327\n",
      "Epoch 22/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.2131 - accuracy: 0.9328\n",
      "Epoch 23/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.2093 - accuracy: 0.9369\n",
      "Epoch 24/100\n",
      "972/972 [==============================] - 1s 727us/step - loss: 0.2060 - accuracy: 0.9370\n",
      "Epoch 25/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.2056 - accuracy: 0.9360\n",
      "Epoch 26/100\n",
      "972/972 [==============================] - 1s 724us/step - loss: 0.1973 - accuracy: 0.9396\n",
      "Epoch 27/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.1941 - accuracy: 0.9412\n",
      "Epoch 28/100\n",
      "972/972 [==============================] - 1s 732us/step - loss: 0.1852 - accuracy: 0.9443\n",
      "Epoch 29/100\n",
      "972/972 [==============================] - 1s 797us/step - loss: 0.1917 - accuracy: 0.9396\n",
      "Epoch 30/100\n",
      "972/972 [==============================] - 1s 732us/step - loss: 0.1868 - accuracy: 0.9401\n",
      "Epoch 31/100\n",
      "972/972 [==============================] - 1s 728us/step - loss: 0.1811 - accuracy: 0.9437\n",
      "Epoch 32/100\n",
      "972/972 [==============================] - 1s 732us/step - loss: 0.1784 - accuracy: 0.9464\n",
      "Epoch 33/100\n",
      "972/972 [==============================] - 1s 720us/step - loss: 0.1760 - accuracy: 0.9453\n",
      "Epoch 34/100\n",
      "972/972 [==============================] - 1s 721us/step - loss: 0.1753 - accuracy: 0.9447\n",
      "Epoch 35/100\n",
      "972/972 [==============================] - 1s 727us/step - loss: 0.1669 - accuracy: 0.9487\n",
      "Epoch 36/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.1770 - accuracy: 0.9444\n",
      "Epoch 37/100\n",
      "972/972 [==============================] - 1s 724us/step - loss: 0.1723 - accuracy: 0.9472\n",
      "Epoch 38/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.1729 - accuracy: 0.9452\n",
      "Epoch 39/100\n",
      "972/972 [==============================] - 1s 728us/step - loss: 0.1633 - accuracy: 0.9483\n",
      "Epoch 40/100\n",
      "972/972 [==============================] - 1s 728us/step - loss: 0.1596 - accuracy: 0.9495\n",
      "Epoch 41/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.1585 - accuracy: 0.9502\n",
      "Epoch 42/100\n",
      "972/972 [==============================] - 1s 730us/step - loss: 0.1508 - accuracy: 0.9542\n",
      "Epoch 43/100\n",
      "972/972 [==============================] - 1s 731us/step - loss: 0.1526 - accuracy: 0.9516\n",
      "Epoch 44/100\n",
      "972/972 [==============================] - 1s 730us/step - loss: 0.1543 - accuracy: 0.9531\n",
      "Epoch 45/100\n",
      "972/972 [==============================] - 1s 733us/step - loss: 0.1494 - accuracy: 0.9530\n",
      "Epoch 46/100\n",
      "972/972 [==============================] - 1s 742us/step - loss: 0.1522 - accuracy: 0.9522\n",
      "Epoch 47/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.1540 - accuracy: 0.9505\n",
      "Epoch 48/100\n",
      "972/972 [==============================] - 1s 731us/step - loss: 0.1461 - accuracy: 0.9548\n",
      "Epoch 49/100\n",
      "972/972 [==============================] - 1s 737us/step - loss: 0.1436 - accuracy: 0.9544\n",
      "Epoch 50/100\n",
      "972/972 [==============================] - 1s 727us/step - loss: 0.1438 - accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "972/972 [==============================] - 1s 797us/step - loss: 0.1480 - accuracy: 0.9519\n",
      "Epoch 52/100\n",
      "972/972 [==============================] - 1s 786us/step - loss: 0.1419 - accuracy: 0.9550\n",
      "Epoch 53/100\n",
      "972/972 [==============================] - 1s 734us/step - loss: 0.1435 - accuracy: 0.9536\n",
      "Epoch 54/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.1388 - accuracy: 0.9579\n",
      "Epoch 55/100\n",
      "972/972 [==============================] - 1s 762us/step - loss: 0.1409 - accuracy: 0.9567\n",
      "Epoch 56/100\n",
      "972/972 [==============================] - 1s 843us/step - loss: 0.1382 - accuracy: 0.9571\n",
      "Epoch 57/100\n",
      "972/972 [==============================] - 1s 998us/step - loss: 0.1349 - accuracy: 0.9586\n",
      "Epoch 58/100\n",
      "972/972 [==============================] - 1s 817us/step - loss: 0.1365 - accuracy: 0.9567\n",
      "Epoch 59/100\n",
      "972/972 [==============================] - 1s 980us/step - loss: 0.1355 - accuracy: 0.9574\n",
      "Epoch 60/100\n",
      "972/972 [==============================] - 1s 891us/step - loss: 0.1330 - accuracy: 0.9568\n",
      "Epoch 61/100\n",
      "972/972 [==============================] - 1s 824us/step - loss: 0.1300 - accuracy: 0.9589\n",
      "Epoch 62/100\n",
      "972/972 [==============================] - 1s 881us/step - loss: 0.1308 - accuracy: 0.9576\n",
      "Epoch 63/100\n",
      "972/972 [==============================] - 1s 825us/step - loss: 0.1385 - accuracy: 0.9557\n",
      "Epoch 64/100\n",
      "972/972 [==============================] - 1s 837us/step - loss: 0.1284 - accuracy: 0.9602\n",
      "Epoch 65/100\n",
      "972/972 [==============================] - 1s 937us/step - loss: 0.1234 - accuracy: 0.9618\n",
      "Epoch 66/100\n",
      "972/972 [==============================] - 1s 809us/step - loss: 0.1297 - accuracy: 0.9599\n",
      "Epoch 67/100\n",
      "972/972 [==============================] - 1s 815us/step - loss: 0.1262 - accuracy: 0.9592\n",
      "Epoch 68/100\n",
      "972/972 [==============================] - 1s 837us/step - loss: 0.1227 - accuracy: 0.9614\n",
      "Epoch 69/100\n",
      "972/972 [==============================] - 1s 815us/step - loss: 0.1223 - accuracy: 0.9617\n",
      "Epoch 70/100\n",
      "972/972 [==============================] - 1s 833us/step - loss: 0.1245 - accuracy: 0.9623\n",
      "Epoch 71/100\n",
      "972/972 [==============================] - 1s 921us/step - loss: 0.1206 - accuracy: 0.9603\n",
      "Epoch 72/100\n",
      "972/972 [==============================] - 1s 842us/step - loss: 0.1205 - accuracy: 0.9612\n",
      "Epoch 73/100\n",
      "972/972 [==============================] - 1s 830us/step - loss: 0.1215 - accuracy: 0.9620\n",
      "Epoch 74/100\n",
      "972/972 [==============================] - 1s 910us/step - loss: 0.1123 - accuracy: 0.9645\n",
      "Epoch 75/100\n",
      "972/972 [==============================] - 1s 741us/step - loss: 0.1117 - accuracy: 0.9654\n",
      "Epoch 76/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.1164 - accuracy: 0.9617\n",
      "Epoch 77/100\n",
      "972/972 [==============================] - 1s 758us/step - loss: 0.1126 - accuracy: 0.9646\n",
      "Epoch 78/100\n",
      "972/972 [==============================] - 1s 839us/step - loss: 0.1146 - accuracy: 0.9634\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972/972 [==============================] - 1s 752us/step - loss: 0.1179 - accuracy: 0.9619\n",
      "Epoch 80/100\n",
      "972/972 [==============================] - 1s 733us/step - loss: 0.1113 - accuracy: 0.9651\n",
      "Epoch 81/100\n",
      "972/972 [==============================] - 1s 755us/step - loss: 0.1119 - accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "972/972 [==============================] - 1s 740us/step - loss: 0.1133 - accuracy: 0.9648\n",
      "Epoch 83/100\n",
      "972/972 [==============================] - 1s 748us/step - loss: 0.1105 - accuracy: 0.9638\n",
      "Epoch 84/100\n",
      "972/972 [==============================] - 1s 748us/step - loss: 0.1077 - accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "972/972 [==============================] - 1s 732us/step - loss: 0.1068 - accuracy: 0.9647\n",
      "Epoch 86/100\n",
      "972/972 [==============================] - 1s 738us/step - loss: 0.1072 - accuracy: 0.9649\n",
      "Epoch 87/100\n",
      "972/972 [==============================] - 1s 742us/step - loss: 0.1058 - accuracy: 0.9658\n",
      "Epoch 88/100\n",
      "972/972 [==============================] - 1s 732us/step - loss: 0.1062 - accuracy: 0.9668\n",
      "Epoch 89/100\n",
      "972/972 [==============================] - 1s 752us/step - loss: 0.1045 - accuracy: 0.9683\n",
      "Epoch 90/100\n",
      "972/972 [==============================] - 1s 742us/step - loss: 0.1016 - accuracy: 0.9674\n",
      "Epoch 91/100\n",
      "972/972 [==============================] - 1s 783us/step - loss: 0.0990 - accuracy: 0.9691\n",
      "Epoch 92/100\n",
      "972/972 [==============================] - 1s 813us/step - loss: 0.1015 - accuracy: 0.9677\n",
      "Epoch 93/100\n",
      "972/972 [==============================] - 1s 764us/step - loss: 0.1038 - accuracy: 0.9679\n",
      "Epoch 94/100\n",
      "972/972 [==============================] - 1s 761us/step - loss: 0.0992 - accuracy: 0.9686\n",
      "Epoch 95/100\n",
      "972/972 [==============================] - 1s 758us/step - loss: 0.0949 - accuracy: 0.97040s - los\n",
      "Epoch 96/100\n",
      "972/972 [==============================] - 1s 752us/step - loss: 0.1020 - accuracy: 0.9680\n",
      "Epoch 97/100\n",
      "972/972 [==============================] - 1s 764us/step - loss: 0.0968 - accuracy: 0.9702\n",
      "Epoch 98/100\n",
      "972/972 [==============================] - 1s 747us/step - loss: 0.0997 - accuracy: 0.9677\n",
      "Epoch 99/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.0997 - accuracy: 0.9676\n",
      "Epoch 100/100\n",
      "972/972 [==============================] - 1s 741us/step - loss: 0.0959 - accuracy: 0.9704\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x297a3d6e1f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(20, )),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(50)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training_text, training_label, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-7c42d552e199>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"PREDICT_RESULT\"][index] = np.argmax(predictions[i])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "test_df[\"PREDICT_RESULT\"] = 0\n",
    "for index, row in test_df.iterrows():\n",
    "    test_df[\"PREDICT_RESULT\"][index] = np.argmax(predictions[i])\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "test_df[\"COMPARE\"] = np.where(test_df[\"AC_TRADE_CODE_INDEX\"] == test_df[\"PREDICT_RESULT\"], True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9328\n",
       "False     994\n",
       "Name: COMPARE, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['COMPARE'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
