{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from numpy import loadtxt\n",
    "from keras.utils import np_utils\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel(\"BQ Analysis v1_1.xlsx\", \"Project BQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 349 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.astype(str)\n",
    "df[\"PREPROCESS_TEXT\"] = df[\"BQ_TRADE\"] + \",\" + df[\"BQ_HEADING\"] + \",\" + df[\"BQ_SUB_HEADING\"] + \",\" + df[\"BQ_ITEM_HEADING\"] + \",\" + df[\"BQ_ITEM_DESCRIPTION\"] #+ \",\" + df[\"AC_TRADE_CODE\"]\n",
    "#df['RESULT'] = \"\"\n",
    "#training_df = df.loc[df['CONTRACT_CODE'] == \"FL49\"].copy() // not enough training data?\n",
    "df = df[df['AC_TRADE_CODE'] != \"DA\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"IP\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"SS\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"EL\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"SO\"]\n",
    "df = df[df['AC_TRADE_CODE'] != \"AS\"]\n",
    "\n",
    "\n",
    "df[\"PREPROCESS_TEXT\"] = list(map(lambda x: x.lower(), list(df[\"PREPROCESS_TEXT\"])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['PS',\n",
    "'ST',\n",
    "'SM',\n",
    "'EL',\n",
    "'PL',\n",
    "'BS',\n",
    "'DR',\n",
    "'CJ',\n",
    "'PA',\n",
    "'AR',\n",
    "'PR',\n",
    "'SO',\n",
    "'GL',\n",
    "'IF',\n",
    "'DW',\n",
    "'EX',\n",
    "'IR',\n",
    "'FD',\n",
    "'AP',\n",
    "'SU',\n",
    "'FF',\n",
    "'SG',\n",
    "'AS',\n",
    "'EF',\n",
    "'BR',\n",
    "'SS',\n",
    "'DA',\n",
    "'IP'\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = df[df['CONTRACT_CODE'] != \"QHP3\"].copy()\n",
    "\n",
    "\n",
    "training_df[\"AC_TRADE_CODE_INDEX\"] = list(map(lambda x: class_names.index(x), list(training_df.AC_TRADE_CODE)))\n",
    "#training_df[\"AC_TRADE_CODE\"].value_counts()\n",
    "#training_df[\"AC_TRADE_CODE_INDEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2788\n",
       "1     2712\n",
       "2     2258\n",
       "4      853\n",
       "6      479\n",
       "8      427\n",
       "7      368\n",
       "9      215\n",
       "12      95\n",
       "10      58\n",
       "24      35\n",
       "16      24\n",
       "15      10\n",
       "Name: AC_TRADE_CODE_INDEX, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df[df['CONTRACT_CODE'] == \"QHP3\"].copy()\n",
    "test_df[\"AC_TRADE_CODE_INDEX\"] = list(map(lambda x: class_names.index(x), list(test_df.AC_TRADE_CODE)))\n",
    "test_df[\"AC_TRADE_CODE_INDEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[\"AC_TRADE_CODE\"]))\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(df[\"AC_TRADE_CODE\"])\n",
    "# training_label = np_utils.to_categorical((label_encoder.transform(df[\"AC_TRADE_CODE\"])))\n",
    "\n",
    "# print(len(training_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized_doc = []\n",
    "# for d in training_df[\"PREPROCESS_TEXT\"]:\n",
    "#     tokenized_doc.append(word_tokenize(d))\n",
    "# tokenized_doc\n",
    "# tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "# len(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model= Doc2Vec.load(\"test_doc2vec.model\")\n",
    "#training_text = model.wv.vectors\n",
    "#print(len(training_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31075\n",
      "[-0.06272464 -0.10067155 -0.4152371  -0.6165283  -0.91595304  0.29419473\n",
      " -0.52807826 -0.9100595  -1.4919195  -0.6168335  -0.48975003  0.31695592\n",
      " -0.11166995 -1.4265729   0.64957315  0.89637214 -0.15140072  0.7948094\n",
      "  0.82698345  1.0828694 ]\n",
      "10322\n",
      "[ 0.4904189   1.2882067  -1.1763126   0.5540634   0.4928528  -1.4700594\n",
      " -0.10427852  0.00327017 -0.38436523 -0.1642787   0.9855542   0.6602815\n",
      "  1.7499673   0.1199621   0.3647239  -0.643064   -0.7047786   1.0265734\n",
      " -0.31217182  2.3166337 ]\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test_data = word_tokenize(df[\"PREPROCESS_TEXT\"])\n",
    "# v1 = model.infer_vector(test_data)\n",
    "# print(\"V1_infer\", v1)\n",
    "\n",
    "training_text = []\n",
    "for index, row in training_df.iterrows():\n",
    "    training_text.append(model.infer_vector(word_tokenize(row[\"PREPROCESS_TEXT\"])))\n",
    "\n",
    "training_text = np.asarray(training_text)  \n",
    "print(len(training_text))\n",
    "print(training_text[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_text = []\n",
    "for index, row in test_df.iterrows():\n",
    "    #print(model.infer_vector(word_tokenize(row[\"PREPROCESS_TEXT\"])))\n",
    "    test_text.append(model.infer_vector(word_tokenize(row[\"PREPROCESS_TEXT\"])))\n",
    "\n",
    "test_text = np.asarray(test_text)  \n",
    "print(len(test_text))\n",
    "print(test_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = np.asarray(training_df[\"AC_TRADE_CODE_INDEX\"])  \n",
    "test_label = np.asarray(test_df[\"AC_TRADE_CODE_INDEX\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31075, 20), (31075,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text.shape, training_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "972/972 [==============================] - 1s 771us/step - loss: 1.4826 - accuracy: 0.6383\n",
      "Epoch 2/100\n",
      "972/972 [==============================] - 1s 736us/step - loss: 0.5793 - accuracy: 0.8259\n",
      "Epoch 3/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.4927 - accuracy: 0.8481\n",
      "Epoch 4/100\n",
      "972/972 [==============================] - 1s 730us/step - loss: 0.4568 - accuracy: 0.8624\n",
      "Epoch 5/100\n",
      "972/972 [==============================] - 1s 734us/step - loss: 0.4142 - accuracy: 0.8752\n",
      "Epoch 6/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.3805 - accuracy: 0.8854\n",
      "Epoch 7/100\n",
      "972/972 [==============================] - 1s 728us/step - loss: 0.3483 - accuracy: 0.8939\n",
      "Epoch 8/100\n",
      "972/972 [==============================] - 1s 723us/step - loss: 0.3377 - accuracy: 0.8969\n",
      "Epoch 9/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.3229 - accuracy: 0.9026\n",
      "Epoch 10/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.3018 - accuracy: 0.9075\n",
      "Epoch 11/100\n",
      "972/972 [==============================] - 1s 717us/step - loss: 0.2918 - accuracy: 0.9121\n",
      "Epoch 12/100\n",
      "972/972 [==============================] - 1s 719us/step - loss: 0.2792 - accuracy: 0.9120\n",
      "Epoch 13/100\n",
      "972/972 [==============================] - 1s 727us/step - loss: 0.2737 - accuracy: 0.9164\n",
      "Epoch 14/100\n",
      "972/972 [==============================] - 1s 723us/step - loss: 0.2650 - accuracy: 0.9174\n",
      "Epoch 15/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.2528 - accuracy: 0.9232\n",
      "Epoch 16/100\n",
      "972/972 [==============================] - 1s 747us/step - loss: 0.2389 - accuracy: 0.9279\n",
      "Epoch 17/100\n",
      "972/972 [==============================] - 1s 778us/step - loss: 0.2370 - accuracy: 0.9285\n",
      "Epoch 18/100\n",
      "972/972 [==============================] - 1s 768us/step - loss: 0.2282 - accuracy: 0.9317\n",
      "Epoch 19/100\n",
      "972/972 [==============================] - 1s 728us/step - loss: 0.2250 - accuracy: 0.9303\n",
      "Epoch 20/100\n",
      "972/972 [==============================] - 1s 720us/step - loss: 0.2208 - accuracy: 0.9303\n",
      "Epoch 21/100\n",
      "972/972 [==============================] - 1s 732us/step - loss: 0.2146 - accuracy: 0.9342\n",
      "Epoch 22/100\n",
      "972/972 [==============================] - 1s 721us/step - loss: 0.2059 - accuracy: 0.9343\n",
      "Epoch 23/100\n",
      "972/972 [==============================] - 1s 734us/step - loss: 0.2021 - accuracy: 0.9364\n",
      "Epoch 24/100\n",
      "972/972 [==============================] - 1s 739us/step - loss: 0.2066 - accuracy: 0.9361\n",
      "Epoch 25/100\n",
      "972/972 [==============================] - 1s 729us/step - loss: 0.1921 - accuracy: 0.9406\n",
      "Epoch 26/100\n",
      "972/972 [==============================] - 1s 724us/step - loss: 0.1892 - accuracy: 0.9411\n",
      "Epoch 27/100\n",
      "972/972 [==============================] - 1s 733us/step - loss: 0.1909 - accuracy: 0.9399\n",
      "Epoch 28/100\n",
      "972/972 [==============================] - 1s 733us/step - loss: 0.1788 - accuracy: 0.9443\n",
      "Epoch 29/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.1806 - accuracy: 0.9426\n",
      "Epoch 30/100\n",
      "972/972 [==============================] - 1s 720us/step - loss: 0.1789 - accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "972/972 [==============================] - 1s 723us/step - loss: 0.1751 - accuracy: 0.9447\n",
      "Epoch 32/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.1722 - accuracy: 0.9457\n",
      "Epoch 33/100\n",
      "972/972 [==============================] - 1s 731us/step - loss: 0.1705 - accuracy: 0.9462\n",
      "Epoch 34/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.1685 - accuracy: 0.9471\n",
      "Epoch 35/100\n",
      "972/972 [==============================] - 1s 730us/step - loss: 0.1675 - accuracy: 0.9493\n",
      "Epoch 36/100\n",
      "972/972 [==============================] - 1s 731us/step - loss: 0.1628 - accuracy: 0.9483\n",
      "Epoch 37/100\n",
      "972/972 [==============================] - 1s 725us/step - loss: 0.1564 - accuracy: 0.9524\n",
      "Epoch 38/100\n",
      "972/972 [==============================] - 1s 726us/step - loss: 0.1524 - accuracy: 0.9528\n",
      "Epoch 39/100\n",
      "972/972 [==============================] - 1s 756us/step - loss: 0.1609 - accuracy: 0.9487\n",
      "Epoch 40/100\n",
      "972/972 [==============================] - 1s 793us/step - loss: 0.1536 - accuracy: 0.9528\n",
      "Epoch 41/100\n",
      "972/972 [==============================] - 1s 742us/step - loss: 0.1517 - accuracy: 0.9530\n",
      "Epoch 42/100\n",
      "972/972 [==============================] - 1s 737us/step - loss: 0.1526 - accuracy: 0.9517\n",
      "Epoch 43/100\n",
      "972/972 [==============================] - 1s 739us/step - loss: 0.1487 - accuracy: 0.9532\n",
      "Epoch 44/100\n",
      "972/972 [==============================] - 1s 741us/step - loss: 0.1514 - accuracy: 0.9505\n",
      "Epoch 45/100\n",
      "972/972 [==============================] - 1s 745us/step - loss: 0.1440 - accuracy: 0.9564\n",
      "Epoch 46/100\n",
      "972/972 [==============================] - 1s 743us/step - loss: 0.1469 - accuracy: 0.9534\n",
      "Epoch 47/100\n",
      "972/972 [==============================] - 1s 746us/step - loss: 0.1410 - accuracy: 0.9572\n",
      "Epoch 48/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.1412 - accuracy: 0.9573\n",
      "Epoch 49/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.1423 - accuracy: 0.9542\n",
      "Epoch 50/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.1392 - accuracy: 0.9562\n",
      "Epoch 51/100\n",
      "972/972 [==============================] - 1s 821us/step - loss: 0.1351 - accuracy: 0.9563\n",
      "Epoch 52/100\n",
      "972/972 [==============================] - 1s 742us/step - loss: 0.1343 - accuracy: 0.9570\n",
      "Epoch 53/100\n",
      "972/972 [==============================] - 1s 719us/step - loss: 0.1288 - accuracy: 0.9586\n",
      "Epoch 54/100\n",
      "972/972 [==============================] - 1s 717us/step - loss: 0.1333 - accuracy: 0.9577\n",
      "Epoch 55/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.1326 - accuracy: 0.9578\n",
      "Epoch 56/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.1307 - accuracy: 0.9578\n",
      "Epoch 57/100\n",
      "972/972 [==============================] - 1s 724us/step - loss: 0.1274 - accuracy: 0.9580\n",
      "Epoch 58/100\n",
      "972/972 [==============================] - 1s 715us/step - loss: 0.1245 - accuracy: 0.9607\n",
      "Epoch 59/100\n",
      "972/972 [==============================] - 1s 729us/step - loss: 0.1195 - accuracy: 0.9628\n",
      "Epoch 60/100\n",
      "972/972 [==============================] - 1s 719us/step - loss: 0.1212 - accuracy: 0.9617\n",
      "Epoch 61/100\n",
      "972/972 [==============================] - 1s 734us/step - loss: 0.1231 - accuracy: 0.9606\n",
      "Epoch 62/100\n",
      "972/972 [==============================] - 1s 783us/step - loss: 0.1217 - accuracy: 0.9609\n",
      "Epoch 63/100\n",
      "972/972 [==============================] - 1s 729us/step - loss: 0.1165 - accuracy: 0.9641\n",
      "Epoch 64/100\n",
      "972/972 [==============================] - 1s 717us/step - loss: 0.1199 - accuracy: 0.9624\n",
      "Epoch 65/100\n",
      "972/972 [==============================] - 1s 717us/step - loss: 0.1169 - accuracy: 0.9639\n",
      "Epoch 66/100\n",
      "972/972 [==============================] - 1s 717us/step - loss: 0.1163 - accuracy: 0.9637\n",
      "Epoch 67/100\n",
      "972/972 [==============================] - 1s 720us/step - loss: 0.1161 - accuracy: 0.9642\n",
      "Epoch 68/100\n",
      "972/972 [==============================] - 1s 714us/step - loss: 0.1188 - accuracy: 0.9634\n",
      "Epoch 69/100\n",
      "972/972 [==============================] - 1s 744us/step - loss: 0.1130 - accuracy: 0.9645\n",
      "Epoch 70/100\n",
      "972/972 [==============================] - 1s 803us/step - loss: 0.1176 - accuracy: 0.9622\n",
      "Epoch 71/100\n",
      "972/972 [==============================] - 1s 737us/step - loss: 0.1116 - accuracy: 0.9636\n",
      "Epoch 72/100\n",
      "972/972 [==============================] - 1s 739us/step - loss: 0.1080 - accuracy: 0.9655\n",
      "Epoch 73/100\n",
      "972/972 [==============================] - 1s 721us/step - loss: 0.1091 - accuracy: 0.9670\n",
      "Epoch 74/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.1120 - accuracy: 0.9637\n",
      "Epoch 75/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.1107 - accuracy: 0.9650\n",
      "Epoch 76/100\n",
      "972/972 [==============================] - 1s 728us/step - loss: 0.1105 - accuracy: 0.9656\n",
      "Epoch 77/100\n",
      "972/972 [==============================] - 1s 719us/step - loss: 0.1070 - accuracy: 0.9652\n",
      "Epoch 78/100\n",
      "972/972 [==============================] - 1s 724us/step - loss: 0.1043 - accuracy: 0.9670\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972/972 [==============================] - 1s 717us/step - loss: 0.1046 - accuracy: 0.9658\n",
      "Epoch 80/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.1053 - accuracy: 0.9657\n",
      "Epoch 81/100\n",
      "972/972 [==============================] - 1s 713us/step - loss: 0.1030 - accuracy: 0.9688\n",
      "Epoch 82/100\n",
      "972/972 [==============================] - 1s 713us/step - loss: 0.1028 - accuracy: 0.9676\n",
      "Epoch 83/100\n",
      "972/972 [==============================] - 1s 711us/step - loss: 0.1030 - accuracy: 0.9687\n",
      "Epoch 84/100\n",
      "972/972 [==============================] - 1s 766us/step - loss: 0.1054 - accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "972/972 [==============================] - 1s 817us/step - loss: 0.0966 - accuracy: 0.9698\n",
      "Epoch 86/100\n",
      "972/972 [==============================] - 1s 739us/step - loss: 0.1062 - accuracy: 0.9658\n",
      "Epoch 87/100\n",
      "972/972 [==============================] - 1s 713us/step - loss: 0.1007 - accuracy: 0.9697\n",
      "Epoch 88/100\n",
      "972/972 [==============================] - 1s 714us/step - loss: 0.1036 - accuracy: 0.9675\n",
      "Epoch 89/100\n",
      "972/972 [==============================] - 1s 718us/step - loss: 0.0950 - accuracy: 0.9697\n",
      "Epoch 90/100\n",
      "972/972 [==============================] - 1s 710us/step - loss: 0.1010 - accuracy: 0.9670\n",
      "Epoch 91/100\n",
      "972/972 [==============================] - 1s 721us/step - loss: 0.0976 - accuracy: 0.9689\n",
      "Epoch 92/100\n",
      "972/972 [==============================] - 1s 713us/step - loss: 0.1045 - accuracy: 0.9676\n",
      "Epoch 93/100\n",
      "972/972 [==============================] - 1s 714us/step - loss: 0.0982 - accuracy: 0.9674\n",
      "Epoch 94/100\n",
      "972/972 [==============================] - 1s 712us/step - loss: 0.0909 - accuracy: 0.9708\n",
      "Epoch 95/100\n",
      "972/972 [==============================] - 1s 715us/step - loss: 0.0944 - accuracy: 0.9710\n",
      "Epoch 96/100\n",
      "972/972 [==============================] - 1s 710us/step - loss: 0.0958 - accuracy: 0.9709\n",
      "Epoch 97/100\n",
      "972/972 [==============================] - 1s 715us/step - loss: 0.0910 - accuracy: 0.9706\n",
      "Epoch 98/100\n",
      "972/972 [==============================] - 1s 714us/step - loss: 0.0897 - accuracy: 0.9723\n",
      "Epoch 99/100\n",
      "972/972 [==============================] - 1s 714us/step - loss: 0.0926 - accuracy: 0.9707\n",
      "Epoch 100/100\n",
      "972/972 [==============================] - 1s 739us/step - loss: 0.0932 - accuracy: 0.9706\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x234a6273f70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(20, )),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(50)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training_text, training_label, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 - 0s - loss: 0.4141 - accuracy: 0.9078\n",
      "\n",
      "Test accuracy: 0.9077697992324829\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_text,  test_label, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-7c42d552e199>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"PREDICT_RESULT\"][index] = np.argmax(predictions[i])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "test_df[\"PREDICT_RESULT\"] = 0\n",
    "for index, row in test_df.iterrows():\n",
    "    test_df[\"PREDICT_RESULT\"][index] = np.argmax(predictions[i])\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "test_df[\"COMPARE\"] = np.where(test_df[\"AC_TRADE_CODE_INDEX\"] == test_df[\"PREDICT_RESULT\"], True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9370\n",
       "False     952\n",
       "Name: COMPARE, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['COMPARE'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
